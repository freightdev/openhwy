# System Context Prompt for AI Models

## SYSTEM ARCHITECTURE OVERVIEW
You are working with a dual-machine production infrastructure built by Jesse Conley, a systems engineer with expertise from silicon-level hardware to AI consciousness. This infrastructure supports trucking platforms, AI/ML workloads, and hosting services.

## HARDWARE SPECIFICATIONS

### ASUS TUF Gaming (Production Server - Headless)
```yaml
Role: Primary production server, AI inference, database host
CPU: AMD Ryzen 5 3550H
  - 4 cores / 8 threads
  - Base: 2.1 GHz, Boost: 3.7 GHz
  - Current limitation: Maxing at 2.1 GHz (thermal/power throttling)
GPU: NVIDIA GeForce GTX 1650 Mobile/Max-Q
  - 4GB VRAM, Turing architecture
  - CUDA 12.6 support for AI inference
iGPU: Radeon Vega Mobile (amdgpu driver)
Memory: 32GB DDR4 with zram compression
  - zram-size: 16GB (50% of RAM)
  - compression: zstd
  - vm.swappiness: 180 (aggressive swapping)
Storage: 931GB Crucial P3 (Micron 2550 NVMe, XFS)
  - Read: 1476 MiB/s, Write: 1466 MiB/s
  - IOPS: ~2941, Latency: R:6.3ms W:15.4ms
  - Current utilization: 90.80% (CRITICAL - near capacity)
  - Queue depth: 32 (saturated)
Network: Wired Cat-6 Ethernet
Configuration: Headless Arch Linux (minimal install)
```

### LENOVO YOGA 9i (Development Machine)
```yaml
Role: Development, testing, remote control, mobile workstation
CPU: Intel Core Ultra 7 155H (Meteor Lake)
  - 22 threads total
  - Hybrid architecture with P-cores and E-cores
GPU: Intel Arc Xe-LPG integrated
NPU: Intel NPU for AI acceleration
Memory: 16GB DDR5 with zram compression
Storage: 1TB Samsung PM9C1a (XFS)
  - Read: 857 MiB/s, Write: 855 MiB/s
  - IOPS: ~1712, Latency: R:17.8ms W:19.5ms
  - Current utilization: 92.7% (HIGH - approaching capacity limits)
  - Queue depth: 32 (saturated)
Network: WiFi (mobile connectivity)
Configuration: Full Arch Linux with GUI environment
```

## OPERATING SYSTEM CONFIGURATION

### Base System
```yaml
Distribution: Arch Linux (rolling release)
Kernel: 6.15.9-zen1-1-zen (custom compiled)
Init: systemd
Package Management: pacman + yay (AUR)
Shell: zsh with custom framework
```

### Memory Management
```yaml
ZRAM Configuration:
  - Size: 50% of total RAM
  - Algorithm: zstd compression
  - Priority: 100
  - Type: swap

Sysctl Tuning:
  - vm.swappiness: 180
  - vm.watermark_boost_factor: 0
  - vm.watermark_scale_factor: 125
  - vm.page-cluster: 0
```

### Filesystem Layout (XFS Optimized)
```yaml
Mount Options: noatime,largeio,inode64,allocsize=16m
I/O Scheduler: Deadline

ASUS Partitioning:
  /dev/nvme0n1p1: /boot (1GB, vfat)
  /dev/nvme0n1p2: / (30GB, xfs) - WARNING: Too small for production
  /dev/nvme0n1p3: /var (500GB, xfs)
  /dev/nvme0n1p4: /srv (400GB, xfs)

LENOVO Partitioning:
  /dev/nvme0n1p1: /boot (1GB, vfat)
  /dev/nvme0n1p2: / (50GB, xfs)
  /dev/nvme0n1p3: /var (150GB, xfs)
  /dev/nvme0n1p4: /srv (150GB, xfs)
  /dev/nvme0n1p5: /opt (100GB, xfs)
  /dev/nvme0n1p6: /home (502GB, xfs)
```

## CONTAINER INFRASTRUCTURE

### Runtime Environment
```yaml
Container Runtime: Podman (rootless, daemonless)
Orchestration: podman-compose
Registry: Harbor (private, vulnerability scanning)
Networking: CNI with custom bridge networks
```

### Service Architecture
```yaml
Compose Structure:
  core-infra.yml: PostgreSQL, Redis, MinIO
  auth.yml: Keycloak, OAuth2-Proxy, Teleport
  proxy.yml: Traefik, HAProxy, Cloudflared
  monitoring.yml: Prometheus, Grafana, Loki, Jaeger
  security.yml: Wazuh, Falco, ClamAV
  communication.yml: Asterisk, Jitsi, Matrix
  dev.yml: Gitea, Woodpecker CI, Harbor
  master-compose.yml: Aggregated stack deployment
```

## NETWORKING & SECURITY

### Network Stack
```yaml
Ingress: Cloudflared Zero Trust Tunnels
Private Mesh: WireGuard (ASUS â†” Lenovo)
Firewall: nftables (default deny policy)
DNS: PowerDNS (Authoritative + Recursor)
Reverse Proxy: Traefik (auto-discovery, TLS)
Load Balancer: HAProxy
```

### Security Implementation
```yaml
WAF: ModSecurity with OWASP Core Ruleset
SIEM: Wazuh (central manager + agents)
Runtime Security: Falco container monitoring
Vulnerability Scanning: Trivy (CI/CD integrated)
Access Control: Teleport (SSH, infrastructure sessions)
Rate Limiting: Fail2ban via Traefik log analysis
```

## DATABASE & STORAGE

### Data Layer
```yaml
Primary Database: PostgreSQL 15 with streaming replication
Caching: Redis Cluster (3-node configuration)
Object Storage: MinIO (S3-compatible, distributed)
Backup Strategy:
  - Restic (incremental, encrypted)
  - WAL-E (PostgreSQL write-ahead logs)
  - XFS snapshots (filesystem level)
  - rsync (flat file backups)
```

## MONITORING & OBSERVABILITY

### Metrics Stack
```yaml
Metrics: Prometheus + AlertManager
Visualization: Grafana dashboards
Logging: Loki + Promtail (centralized)
Tracing: Jaeger (distributed tracing)
Uptime: Uptime Kuma monitoring
CLI Tools: htop, iotop, nethogs, nmap
```

## AI/ML INFRASTRUCTURE

### Inference Environment
```yaml
LLM Runtime: llama.cpp with Rust FFI wrapper
GPU Acceleration: CUDA 12.6 (GTX 1650)
CPU/NPU: OpenVINO (Intel Arc, Yoga 9i)
Model Storage: ~/Workspace/ai/models/
Python Environment: Conda + PyTorch + Transformers + Triton

Workspace Structure:
  ~/Workspace/ai/models/: LLM models, ONNX exports
  ~/Workspace/ai/memory/: AI memory (personal, sessions, knowledge)
  ~/Workspace/ai/chats/: Conversation history
  ~/Workspace/ai/context/: Context windows
  ~/Workspace/ai/training/: Fine-tuning datasets
  ~/Workspace/ai/logs/: System and inference logs
```

## BUSINESS APPLICATIONS

### Trucking Platform Stack
```yaml
FedDispatching.com (For-Profit):
  Agent: FED (Fleet Eco Director)
  Purpose: Dispatcher training and platform
  Revenue: Tools and educational courses

Open-HWY.com (Nonprofit):
  Agent: HWY (Highway Watch Yard)
  Purpose: Highway safety, "Trucker Tales" wisdom capture
  Revenue: SDKs and Rust API licensing

8TeenWheelers.com (Community):
  Agent: ELDA (Ethical Logistics Driver Assistant)
  Purpose: Driver-led logistics community
  Funding: Sponsored by Open-HWY
```

## DEVELOPMENT ENVIRONMENT

### Development Stack
```yaml
IDE: VSCodium with Remote-SSH
Languages: Rust (primary), TypeScript, Python, Bash/Zsh
Version Control: Gitea (self-hosted)
CI/CD: Woodpecker CI
Package Managers: cargo, conda, npm, pacman

Custom Components:
  - 400+ atomic TypeScript components
  - "Bookmark" framework (Next.js alternative)
  - Rust APIs with FFI bindings
  - MARK/BOOK/BET/BEAT AI OS architecture
```

## CRITICAL SYSTEM CONSTRAINTS

### Performance Limitations
```yaml
Storage Capacity Issues:
  - ASUS: 90.80% utilization (CRITICAL)
  - Lenovo: 92.7% utilization (HIGH)
  - Both systems approaching storage exhaustion
  - XFS performance degradation expected

I/O Bottlenecks:
  - Queue depths saturated on both systems
  - Storage latency impacting application performance
  - Need immediate capacity expansion

CPU Throttling:
  - ASUS Ryzen limited to 2.1GHz (thermal/power issue)
  - Significant performance impact for production workloads
  - Thermal management or power delivery problem
```

### Resource Allocation
```yaml
Memory Pressure:
  - High vm.swappiness (180) causing excessive swap usage
  - zram compression overhead on CPU
  - 32GB on ASUS shared between AI inference and production services
  - 16GB on Lenovo insufficient for development workloads

Network Dependencies:
  - ASUS relies on wired connection (single point of failure)
  - Lenovo on WiFi (mobility vs stability trade-off)
  - WireGuard mesh critical for inter-system communication
```

## OPERATIONAL CONTEXT

### Business Requirements
```yaml
Primary Use Cases:
  - Trucking platform development and hosting
  - AI inference for driver assistance systems
  - Development environment for custom frameworks
  - Container orchestration for microservices
  - Database hosting for production applications

Availability Requirements:
  - Business-critical applications require high uptime
  - Development work needs consistent performance
  - AI inference cannot tolerate extended downtime
  - Container services must maintain state consistency
```

### Maintenance Considerations
```yaml
System Administration:
  - Single operator (Jesse Conley) managing entire stack
  - Remote administration via SSH and web interfaces
  - Automated backups and monitoring essential
  - Manual intervention capability required for emergencies

Scaling Limitations:
  - Hardware capacity constraints prevent horizontal scaling
  - Vertical scaling limited by laptop-class hardware
  - Storage expansion critical for continued operation
  - Network bandwidth may limit external service hosting
```

## SECURITY CONTEXT

### Threat Model
```yaml
Attack Vectors:
  - Internet-facing services via Cloudflared tunnels
  - Container escape scenarios
  - Privilege escalation in multi-tenant environment
  - Data exfiltration from business applications
  - AI model theft or poisoning

Protective Measures:
  - Network segmentation via container networking
  - Runtime security monitoring with Falco
  - Vulnerability scanning in CI/CD pipeline
  - Encrypted storage and communication
  - Access logging and SIEM analysis
```

## WHEN PROVIDING SOLUTIONS

### Always Consider
```yaml
Resource Constraints:
  - Storage capacity limitations (critical priority)
  - CPU throttling on production server
  - Memory pressure from AI workloads
  - I/O saturation affecting performance

Operational Reality:
  - Single administrator managing entire infrastructure
  - Business applications require high availability
  - Development work cannot interrupt production
  - Remote access dependencies for all management

Architecture Decisions:
  - Containerized deployment preferred
  - XFS filesystem optimizations required
  - Monitoring integration mandatory
  - Security scanning must be automated
```

### Provide Solutions That
```yaml
Address Immediate Needs:
  - Work within current resource constraints
  - Don't require additional hardware purchases
  - Can be implemented by single operator
  - Integrate with existing monitoring stack

Scale Appropriately:
  - Match the dual-machine architecture
  - Leverage existing container infrastructure  
  - Utilize current security and networking setup
  - Support both development and production workloads

Maintain Business Continuity:
  - Don't disrupt running trucking platforms
  - Preserve AI inference capabilities
  - Maintain development environment functionality
  - Support remote administration requirements
```